---
layout: article
title:  "「CV」 目标检测 Trick"
date:   2020-10-26 14:00:40 +0800
key: ObjectDetection-trick
aside:
  toc: true
category: [AI, CV, detection]
---
<span id='head'> </span>
>[目标检测资源](/ai/cv/detection/2019/05/10/foundation.html)、[目标检测概述](/ai/cv/detection/2020/06/04/survey.html)         
模型的调参训练技巧其实说白了就是怎么让模型得到的是数据全集的稀疏分布，且和别的类别有比较好的区分，也就是类内差小类间差则尽量大。以这个为核心，告诉模型应该关注什么，少关注什么，既然是数据的科学，多关注数据的分布和呈现的状态    


<!--more-->  
预训练、调参

# 1 预处理
## 1.1 图像增强

| 操作 | 效果 |
| --- | --- |
| 仿射变换、裁剪、翻转、扩充、颜色抖动 | 丰富样本的分布 |
| 叠加：高斯、椒盐 | 提升对有干扰、成像质量差的检出能力 |
| 边缘增强：canny | |
| 擦除：一块 | BFENet，应对遮挡情况 |
| Mix up |  |
| Cut up |  |
| Random earse |  |
| CutMix |  |
| 物体的随机粘贴 |  |
| 多尺度训练：多尺度输入|  |
|  |  |
|  |  |


## 1.2 数据融合

# 2 超参
标注框，外扩几个像素，模型精度会更稳定；

## 2.1 anchor
yolo：ground truth 聚类；    
有人问过我为啥我只训练一类的检测，然后重新计算的anchor6个或者9个anchor尺寸差的都不大，但是在实际检测的时候，却检测不到东西。我的结论是：对anchor的设计应该是基于模型作者默认的anchor进行微调而不是完全的重新计算；     
原因：大家都知道，yolov3来说，输出是三个特征图，分别对应小目标，中目标和大目标。比如我们要检测的目标在图像中占比我们人眼感觉应该是比较大的，然后我们统计的框也都是比较大的尺寸，但是在实际训练的时候，并不是说大目标就一定由yolov3的最初设计的大目标输出层输出的。很可能就是由中间目标层输出的，而因为anchor的设计过大，导致训练的网络不收敛的有之，明明收敛了，却检测不到目标的情况也有之；    

解决办法：在设计anchor的时候，首先统计目标框的分布，然后进行聚类，聚类后替换或修改原有的9个anchor中和你计算的anchor相近的几个原有的anchor值。然后再训练，如果框还是不够紧缩，再对某几个框进行精调就可以了，核心思路就是：anchor的分布也要满足对全集的稀疏覆盖而不仅仅是你的当前数据集；     

## 2.2 学习率衰减
学习率的衰减，有很多的方式，按已迭代步长的，按当前损失值的，按训练集当前损失值和测试集计算的损失值的gap差值做修正项的；   
那么，什么时候自动调整，什么时候手动调整；   


# 3 训练策略
## 3.1 基本技巧
Warm Up   
Multi Scale Training/Testing   
Cosine学习率衰减   
large batch BN   
DropOut, DropPath，Spatial DropOut ，DropBlock   
BN、CGBN、GN、LN、CmBN   
L1/L2   
Early stopping   

## 3.2 大数据下训练模型
用比较少的数据训练的时候很快到了97%的MAP，但是换300w的大数据集的训练以后，卡在93%上不去了；    
warm up，也就是说在大数据下训练模型的时候，可以先从大数据集上取一部分数据训练模型，然后以这个训练的模型为预训练模型，在大数据集上，增大batch_size再进行训练，至少没卡在93%这个问题上了；     

损失函数变化曲线图，在曲线图中，数据集的稀疏程度能通过损失曲线的震荡情况有一定的反映，如果有个别的跳点，多为数据集中的坏数据（标记错误数据），当我们的损失图呈现为震荡--阶跃--在另一个损失值附近震荡时，就要注意了，此时多半是因为你的数据集在做打乱的时候数据并没有打的很散，可以在这个位置先停止训练并记录当前状态，再降低学习率，继续训练，等训练数据再次开始恢复之前的震荡位置时，再恢复学习率训练；    

这样操作的原因是为了避免在参数中引入过大的噪声，噪声分两种，一种就是错误的数据，比如背景啊，像目标但是不是目标的东西，还有就是多类别训练的时候，对每个类别来说，其余类别也算是噪声的一种。所以采用要么把数据集弄好（这个很难，我也没看过谁的文章里真的能说清把训练集弄好是啥样的），要么加大batch，要么就训练时候注意；    

## 3.3 困难样本挖掘
OHEM    
S-OHEM    

# 4 模型
## 4.1 loss
Label Smoothing   

# 5 后处理
## 5.1 nms
关注一下两个框的中心点距离，可以设置中心点距离超过多少的两个框，不做nms；这样就能避免挨的近的物体被优化掉；     

# 6 提升定位精度
IOU Loss、GIOU Loss、CIOU Loss、DIOU Loss   
Soft NMS、Softer NMS    
Balanced L1 Loss   

-------------------  
[End](#head)
{:.warning}  


# 附录
## A 参考资料
1. [目标检测比赛中的tricks](https://zhuanlan.zhihu.com/p/102817180)
1. [目标检测比赛提高mAP的方法](https://www.cnblogs.com/zi-wang/p/12537034.html)    
1. GiantPandaCV. 【无痛涨点】目标检测优化的实用Trick[EB/OL]. <https://www.ershicimi.com/p/e79b17d878d438648a059f5b999b86c9>. 2020-09-15/2020-10-26.  
